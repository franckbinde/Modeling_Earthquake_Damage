{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Richter's Predictor: Modeling Earthquake Damage\n",
    "\n",
    "This was a competition hosted by [drivendata.org](https://www.drivendata.org)\n",
    "\n",
    "## Overview\n",
    "Based on aspects of building location and construction, the goal is to predict the level of damage to buildings caused by the 2015 Gorkha earthquake in Nepal.\n",
    "\n",
    "The data was collected through surveys by the Central Bureau of Statistics that work under the National Planning Commission Secretariat of Nepal. This survey is one of the largest post-disaster datasets ever collected, containing valuable information on earthquake impacts, household conditions, and socio-economic-demographic statistics.\n",
    "\n",
    "## Problem description\n",
    "We're trying to predict the ordinal variable damage_grade, which represents a level of damage to the building that was hit by the earthquake. There are 3 grades of the damage:\n",
    "\n",
    " - **1** represents low damage\n",
    " - **2** represents a medium amount of damage\n",
    " - **3** represents almost complete destruction\n",
    " \n",
    "## Features\n",
    "The dataset mainly consists of information on the buildings' structure and their legal ownership. Each row in the dataset represents a specific building in the region that was hit by Gorkha earthquake.\n",
    "\n",
    "There are 39 columns in this dataset, where the building_id column is a unique and random identifier. The remaining 38 features are described in the section below. Categorical variables have been obfuscated random lowercase ascii characters. The appearance of the same character in distinct columns does not imply the same original value.\n",
    "\n",
    "## Description\n",
    "\n",
    "- geo_level_1_id, geo_level_2_id, geo_level_3_id (type: int): geographic region in which building exists, from largest (level 1) to most specific sub-region (level 3). Possible values: level 1: 0-30, level 2: 0-1427, level 3: 0-12567.\n",
    "\n",
    "- count_floors_pre_eq (type: int): number of floors in the building before the earthquake.\n",
    "\n",
    "- age (type: int): age of the building in years.\n",
    "\n",
    "- area_percentage (type: int): normalized area of the building footprint.\n",
    "\n",
    "- height_percentage (type: int): normalized height of the building footprint.\n",
    "\n",
    "- land_surface_condition (type: categorical): surface condition of the land where the building was built. Possible values: n, o, t.\n",
    "\n",
    "- foundation_type (type: categorical): type of foundation used while building. Possible values: h, i, r, u, w.\n",
    "\n",
    "- roof_type (type: categorical): type of roof used while building. Possible values: n, q, x.\n",
    "\n",
    "- ground_floor_type (type: categorical): type of the ground floor. Possible values: f, m, v, x, z.\n",
    "\n",
    "- other_floor_type (type: categorical): type of constructions used in higher than the ground floors (except of roof). Possible values: j, q, s, x.\n",
    "\n",
    "- position (type: categorical): position of the building. Possible values: j, o, s, t.\n",
    "\n",
    "- plan_configuration (type: categorical): building plan configuration. Possible values: a, c, d, f, m, n, o, q, s, u.\n",
    "\n",
    "- has_superstructure_adobe_mud (type: binary): flag variable that indicates if the superstructure was made of Adobe/Mud.\n",
    "\n",
    "- has_superstructure_mud_mortar_stone (type: binary): flag variable that indicates if the superstructure was made of Mud Mortar Stone.\n",
    "\n",
    "- has_superstructure_stone_flag (type: binary): flag variable that indicates if the superstructure was made of Stone.\n",
    "\n",
    "- has_superstructure_cement_mortar_stone (type: binary): flag variable that indicates if the superstructure was made of Cement Mortar - Stone.\n",
    "\n",
    "- has_superstructure_mud_mortar_brick (type: binary): flag variable that indicates if the superstructure was made of Mud Mortar - Brick.\n",
    "\n",
    "- has_superstructure_cement_mortar_brick (type: binary): flag variable that indicates if the superstructure was made of Cement Mortar - Brick.\n",
    "\n",
    "- has_superstructure_timber (type: binary): flag variable that indicates if the superstructure was made of Timber.\n",
    "\n",
    "- has_superstructure_bamboo (type: binary): flag variable that indicates if the superstructure was made of Bamboo.\n",
    "\n",
    "- has_superstructure_rc_non_engineered (type: binary): flag variable that indicates if the superstructure was made of non-engineered reinforced concrete.\n",
    "\n",
    "- has_superstructure_rc_engineered (type: binary): flag variable that indicates if the superstructure was made of engineered reinforced concrete.\n",
    "\n",
    "- has_superstructure_other (type: binary): flag variable that indicates if the superstructure was made of any other material.\n",
    "- legal_ownership_status (type: categorical): legal ownership status of the land where building was built. Possible values: a, r, v, w.\n",
    "\n",
    "- count_families (type: int): number of families that live in the building.\n",
    "\n",
    "- has_secondary_use (type: binary): flag variable that indicates if the building was used for any secondary purpose.\n",
    "\n",
    "- has_secondary_use_agriculture (type: binary): flag variable that indicates if the building was used for agricultural purposes.\n",
    "\n",
    "- has_secondary_use_hotel (type: binary): flag variable that indicates if the building was used as a hotel.\n",
    "\n",
    "- has_secondary_use_rental (type: binary): flag variable that indicates if the building was used for rental purposes.\n",
    "\n",
    "- has_secondary_use_institution (type: binary): flag variable that indicates if the building was used as a location of any institution.\n",
    "\n",
    "- has_secondary_use_school (type: binary): flag variable that indicates if the building was used as a school.\n",
    "\n",
    "- has_secondary_use_industry (type: binary): flag variable that indicates if the building was used for industrial purposes.\n",
    "\n",
    "- has_secondary_use_health_post (type: binary): flag variable that indicates if the building was used as a health post.\n",
    "\n",
    "- has_secondary_use_gov_office (type: binary): flag variable that indicates if the building was used fas a government office.\n",
    "\n",
    "- has_secondary_use_use_police (type: binary): flag variable that indicates if the building was used as a police station.\n",
    "\n",
    "- has_secondary_use_other (type: binary): flag variable that indicates if the building was secondarily used for other purposes.\n",
    "\n",
    "## Performance metric\n",
    "\n",
    "We are predicting the level of damage from 1 to 3. The level of damage is an ordinal variable meaning that ordering is important. This can be viewed as a classification or an ordinal regression problem. (Ordinal regression is sometimes described as an problem somewhere in between classification and regression.)\n",
    "\n",
    "To measure the performance of our algorithms, we'll use the F1 score which balances the precision and recall of a classifier. Traditionally, the F1 score is used to evaluate performance on a binary classifier, but since we have three possible labels we will use a variant called the micro averaged F1 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary modules\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Reading the training data into a dataframe\n",
    "\n",
    "train_values = pd.read_csv('C:/Users/user/Documents/1. E-Learning/2019 Program/Data Science Machine Learning and Deep Learning/Driven Data/Modeling EarthQuake Damage/train_values.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>land_surface_condition</th>\n",
       "      <th>foundation_type</th>\n",
       "      <th>...</th>\n",
       "      <th>has_secondary_use_agriculture</th>\n",
       "      <th>has_secondary_use_hotel</th>\n",
       "      <th>has_secondary_use_rental</th>\n",
       "      <th>has_secondary_use_institution</th>\n",
       "      <th>has_secondary_use_school</th>\n",
       "      <th>has_secondary_use_industry</th>\n",
       "      <th>has_secondary_use_health_post</th>\n",
       "      <th>has_secondary_use_gov_office</th>\n",
       "      <th>has_secondary_use_use_police</th>\n",
       "      <th>has_secondary_use_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>802906</td>\n",
       "      <td>6</td>\n",
       "      <td>487</td>\n",
       "      <td>12198</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28830</td>\n",
       "      <td>8</td>\n",
       "      <td>900</td>\n",
       "      <td>2812</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94947</td>\n",
       "      <td>21</td>\n",
       "      <td>363</td>\n",
       "      <td>8973</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>590882</td>\n",
       "      <td>22</td>\n",
       "      <td>418</td>\n",
       "      <td>10694</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201944</td>\n",
       "      <td>11</td>\n",
       "      <td>131</td>\n",
       "      <td>1488</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id  geo_level_1_id  geo_level_2_id  geo_level_3_id  \\\n",
       "0       802906               6             487           12198   \n",
       "1        28830               8             900            2812   \n",
       "2        94947              21             363            8973   \n",
       "3       590882              22             418           10694   \n",
       "4       201944              11             131            1488   \n",
       "\n",
       "   count_floors_pre_eq  age  area_percentage  height_percentage  \\\n",
       "0                    2   30                6                  5   \n",
       "1                    2   10                8                  7   \n",
       "2                    2   10                5                  5   \n",
       "3                    2   10                6                  5   \n",
       "4                    3   30                8                  9   \n",
       "\n",
       "  land_surface_condition foundation_type  ... has_secondary_use_agriculture  \\\n",
       "0                      t               r  ...                             0   \n",
       "1                      o               r  ...                             0   \n",
       "2                      t               r  ...                             0   \n",
       "3                      t               r  ...                             0   \n",
       "4                      t               r  ...                             0   \n",
       "\n",
       "  has_secondary_use_hotel has_secondary_use_rental  \\\n",
       "0                       0                        0   \n",
       "1                       0                        0   \n",
       "2                       0                        0   \n",
       "3                       0                        0   \n",
       "4                       0                        0   \n",
       "\n",
       "  has_secondary_use_institution has_secondary_use_school  \\\n",
       "0                             0                        0   \n",
       "1                             0                        0   \n",
       "2                             0                        0   \n",
       "3                             0                        0   \n",
       "4                             0                        0   \n",
       "\n",
       "   has_secondary_use_industry  has_secondary_use_health_post  \\\n",
       "0                           0                              0   \n",
       "1                           0                              0   \n",
       "2                           0                              0   \n",
       "3                           0                              0   \n",
       "4                           0                              0   \n",
       "\n",
       "   has_secondary_use_gov_office  has_secondary_use_use_police  \\\n",
       "0                             0                             0   \n",
       "1                             0                             0   \n",
       "2                             0                             0   \n",
       "3                             0                             0   \n",
       "4                             0                             0   \n",
       "\n",
       "   has_secondary_use_other  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the first rows of the dataframe\n",
    "train_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the training labels into a dataframe\n",
    "\n",
    "train_labels = pd.read_csv('C:/Users/user/Documents/1. E-Learning/2019 Program/Data Science Machine Learning and Deep Learning/Driven Data/Modeling EarthQuake Damage/train_labels.csv')\n",
    "train_labels = train_labels['damage_grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 260601 entries, 0 to 260600\n",
      "Data columns (total 39 columns):\n",
      "building_id                               260601 non-null int64\n",
      "geo_level_1_id                            260601 non-null int64\n",
      "geo_level_2_id                            260601 non-null int64\n",
      "geo_level_3_id                            260601 non-null int64\n",
      "count_floors_pre_eq                       260601 non-null int64\n",
      "age                                       260601 non-null int64\n",
      "area_percentage                           260601 non-null int64\n",
      "height_percentage                         260601 non-null int64\n",
      "land_surface_condition                    260601 non-null object\n",
      "foundation_type                           260601 non-null object\n",
      "roof_type                                 260601 non-null object\n",
      "ground_floor_type                         260601 non-null object\n",
      "other_floor_type                          260601 non-null object\n",
      "position                                  260601 non-null object\n",
      "plan_configuration                        260601 non-null object\n",
      "has_superstructure_adobe_mud              260601 non-null int64\n",
      "has_superstructure_mud_mortar_stone       260601 non-null int64\n",
      "has_superstructure_stone_flag             260601 non-null int64\n",
      "has_superstructure_cement_mortar_stone    260601 non-null int64\n",
      "has_superstructure_mud_mortar_brick       260601 non-null int64\n",
      "has_superstructure_cement_mortar_brick    260601 non-null int64\n",
      "has_superstructure_timber                 260601 non-null int64\n",
      "has_superstructure_bamboo                 260601 non-null int64\n",
      "has_superstructure_rc_non_engineered      260601 non-null int64\n",
      "has_superstructure_rc_engineered          260601 non-null int64\n",
      "has_superstructure_other                  260601 non-null int64\n",
      "legal_ownership_status                    260601 non-null object\n",
      "count_families                            260601 non-null int64\n",
      "has_secondary_use                         260601 non-null int64\n",
      "has_secondary_use_agriculture             260601 non-null int64\n",
      "has_secondary_use_hotel                   260601 non-null int64\n",
      "has_secondary_use_rental                  260601 non-null int64\n",
      "has_secondary_use_institution             260601 non-null int64\n",
      "has_secondary_use_school                  260601 non-null int64\n",
      "has_secondary_use_industry                260601 non-null int64\n",
      "has_secondary_use_health_post             260601 non-null int64\n",
      "has_secondary_use_gov_office              260601 non-null int64\n",
      "has_secondary_use_use_police              260601 non-null int64\n",
      "has_secondary_use_other                   260601 non-null int64\n",
      "dtypes: int64(31), object(8)\n",
      "memory usage: 77.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Getting basic infos about the training features\n",
    "train_values.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Feature selection is a critical part of machine learning. There are several ways to select the most relevant features for a prediction. For instance, one could use the **Recursive Feature Elimination (RFE)** algorithm. We could also use a **LightGBM**, or an **XGBoost** object as long it has a feature_importances_ attribute. The **Pearson Correlation**, which is a filter-based method, could help us to keep the features which have the highest correlation with the target variable. \n",
    "\n",
    "However, we have decided to keep certain specific columns as features. This selection was based on a general understanding of the subject, done after some research. Nevertheless, it's important to keep in mind that this selection could be improved with experimentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 260601 entries, 0 to 260600\n",
      "Data columns (total 17 columns):\n",
      "geo_level_1_id                            260601 non-null int64\n",
      "geo_level_2_id                            260601 non-null int64\n",
      "geo_level_3_id                            260601 non-null int64\n",
      "foundation_type                           260601 non-null object\n",
      "position                                  260601 non-null object\n",
      "plan_configuration                        260601 non-null object\n",
      "has_superstructure_adobe_mud              260601 non-null int64\n",
      "has_superstructure_mud_mortar_stone       260601 non-null int64\n",
      "has_superstructure_stone_flag             260601 non-null int64\n",
      "has_superstructure_cement_mortar_stone    260601 non-null int64\n",
      "has_superstructure_mud_mortar_brick       260601 non-null int64\n",
      "has_superstructure_cement_mortar_brick    260601 non-null int64\n",
      "has_superstructure_timber                 260601 non-null int64\n",
      "has_superstructure_bamboo                 260601 non-null int64\n",
      "has_superstructure_rc_engineered          260601 non-null int64\n",
      "has_superstructure_rc_non_engineered      260601 non-null int64\n",
      "has_superstructure_other                  260601 non-null int64\n",
      "dtypes: int64(14), object(3)\n",
      "memory usage: 33.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Selecting the features\n",
    "features = ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id', 'foundation_type', 'position', 'plan_configuration', 'has_superstructure_adobe_mud', 'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag', 'has_superstructure_cement_mortar_stone', 'has_superstructure_mud_mortar_brick', 'has_superstructure_cement_mortar_brick', 'has_superstructure_timber', 'has_superstructure_bamboo', 'has_superstructure_rc_engineered', 'has_superstructure_rc_non_engineered', 'has_superstructure_other']\n",
    "train_values = train_values[features]\n",
    "\n",
    "train_values.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>has_superstructure_adobe_mud</th>\n",
       "      <th>has_superstructure_mud_mortar_stone</th>\n",
       "      <th>has_superstructure_stone_flag</th>\n",
       "      <th>has_superstructure_cement_mortar_stone</th>\n",
       "      <th>has_superstructure_mud_mortar_brick</th>\n",
       "      <th>has_superstructure_cement_mortar_brick</th>\n",
       "      <th>has_superstructure_timber</th>\n",
       "      <th>has_superstructure_bamboo</th>\n",
       "      <th>has_superstructure_rc_engineered</th>\n",
       "      <th>has_superstructure_rc_non_engineered</th>\n",
       "      <th>has_superstructure_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.900353</td>\n",
       "      <td>701.074685</td>\n",
       "      <td>6257.876148</td>\n",
       "      <td>0.088645</td>\n",
       "      <td>0.761935</td>\n",
       "      <td>0.034332</td>\n",
       "      <td>0.018235</td>\n",
       "      <td>0.068154</td>\n",
       "      <td>0.075268</td>\n",
       "      <td>0.254988</td>\n",
       "      <td>0.085011</td>\n",
       "      <td>0.015859</td>\n",
       "      <td>0.042590</td>\n",
       "      <td>0.014985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.033617</td>\n",
       "      <td>412.710734</td>\n",
       "      <td>3646.369645</td>\n",
       "      <td>0.284231</td>\n",
       "      <td>0.425900</td>\n",
       "      <td>0.182081</td>\n",
       "      <td>0.133800</td>\n",
       "      <td>0.252010</td>\n",
       "      <td>0.263824</td>\n",
       "      <td>0.435855</td>\n",
       "      <td>0.278899</td>\n",
       "      <td>0.124932</td>\n",
       "      <td>0.201931</td>\n",
       "      <td>0.121491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>3073.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>702.000000</td>\n",
       "      <td>6270.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>9412.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>1427.000000</td>\n",
       "      <td>12567.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       geo_level_1_id  geo_level_2_id  geo_level_3_id  \\\n",
       "count   260601.000000   260601.000000   260601.000000   \n",
       "mean        13.900353      701.074685     6257.876148   \n",
       "std          8.033617      412.710734     3646.369645   \n",
       "min          0.000000        0.000000        0.000000   \n",
       "25%          7.000000      350.000000     3073.000000   \n",
       "50%         12.000000      702.000000     6270.000000   \n",
       "75%         21.000000     1050.000000     9412.000000   \n",
       "max         30.000000     1427.000000    12567.000000   \n",
       "\n",
       "       has_superstructure_adobe_mud  has_superstructure_mud_mortar_stone  \\\n",
       "count                 260601.000000                        260601.000000   \n",
       "mean                       0.088645                             0.761935   \n",
       "std                        0.284231                             0.425900   \n",
       "min                        0.000000                             0.000000   \n",
       "25%                        0.000000                             1.000000   \n",
       "50%                        0.000000                             1.000000   \n",
       "75%                        0.000000                             1.000000   \n",
       "max                        1.000000                             1.000000   \n",
       "\n",
       "       has_superstructure_stone_flag  has_superstructure_cement_mortar_stone  \\\n",
       "count                  260601.000000                           260601.000000   \n",
       "mean                        0.034332                                0.018235   \n",
       "std                         0.182081                                0.133800   \n",
       "min                         0.000000                                0.000000   \n",
       "25%                         0.000000                                0.000000   \n",
       "50%                         0.000000                                0.000000   \n",
       "75%                         0.000000                                0.000000   \n",
       "max                         1.000000                                1.000000   \n",
       "\n",
       "       has_superstructure_mud_mortar_brick  \\\n",
       "count                        260601.000000   \n",
       "mean                              0.068154   \n",
       "std                               0.252010   \n",
       "min                               0.000000   \n",
       "25%                               0.000000   \n",
       "50%                               0.000000   \n",
       "75%                               0.000000   \n",
       "max                               1.000000   \n",
       "\n",
       "       has_superstructure_cement_mortar_brick  has_superstructure_timber  \\\n",
       "count                           260601.000000              260601.000000   \n",
       "mean                                 0.075268                   0.254988   \n",
       "std                                  0.263824                   0.435855   \n",
       "min                                  0.000000                   0.000000   \n",
       "25%                                  0.000000                   0.000000   \n",
       "50%                                  0.000000                   0.000000   \n",
       "75%                                  0.000000                   1.000000   \n",
       "max                                  1.000000                   1.000000   \n",
       "\n",
       "       has_superstructure_bamboo  has_superstructure_rc_engineered  \\\n",
       "count              260601.000000                     260601.000000   \n",
       "mean                    0.085011                          0.015859   \n",
       "std                     0.278899                          0.124932   \n",
       "min                     0.000000                          0.000000   \n",
       "25%                     0.000000                          0.000000   \n",
       "50%                     0.000000                          0.000000   \n",
       "75%                     0.000000                          0.000000   \n",
       "max                     1.000000                          1.000000   \n",
       "\n",
       "       has_superstructure_rc_non_engineered  has_superstructure_other  \n",
       "count                         260601.000000             260601.000000  \n",
       "mean                               0.042590                  0.014985  \n",
       "std                                0.201931                  0.121491  \n",
       "min                                0.000000                  0.000000  \n",
       "25%                                0.000000                  0.000000  \n",
       "50%                                0.000000                  0.000000  \n",
       "75%                                0.000000                  0.000000  \n",
       "max                                1.000000                  1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print summary statistics \n",
    "train_values.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Variables\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['foundation_type', 'position', 'plan_configuration'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the categorical variables\n",
    "categorical_values = train_values.select_dtypes(include=['object'])\n",
    "print(\"Categorical Variables\")\n",
    "print(\"-------------------------------------------------\")\n",
    "categorical_values.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Variables\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id',\n",
       "       'has_superstructure_adobe_mud', 'has_superstructure_mud_mortar_stone',\n",
       "       'has_superstructure_stone_flag',\n",
       "       'has_superstructure_cement_mortar_stone',\n",
       "       'has_superstructure_mud_mortar_brick',\n",
       "       'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
       "       'has_superstructure_bamboo', 'has_superstructure_rc_engineered',\n",
       "       'has_superstructure_rc_non_engineered', 'has_superstructure_other'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the numeric variables\n",
    "numeric_values = train_values.select_dtypes(include=['int64'])\n",
    "print(\"Numeric Variables\")\n",
    "print(\"-------------------------------------------------\")\n",
    "numeric_values.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the categorical variables\n",
    "\n",
    "categorical_encoded = pd.get_dummies(categorical_values, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature                Data_Type\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "foundation_type_i       uint8\n",
       "foundation_type_r       uint8\n",
       "foundation_type_u       uint8\n",
       "foundation_type_w       uint8\n",
       "position_o              uint8\n",
       "position_s              uint8\n",
       "position_t              uint8\n",
       "plan_configuration_c    uint8\n",
       "plan_configuration_d    uint8\n",
       "plan_configuration_f    uint8\n",
       "plan_configuration_m    uint8\n",
       "plan_configuration_n    uint8\n",
       "plan_configuration_o    uint8\n",
       "plan_configuration_q    uint8\n",
       "plan_configuration_s    uint8\n",
       "plan_configuration_u    uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the types of the variables after encoding\n",
    "print(\"Feature                Data_Type\")\n",
    "print(\"---------------------------------\")\n",
    "categorical_encoded.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the final dataset, by concatenating the numeric and encoded categorical variables\n",
    "new_data = pd.concat([numeric_values, categorical_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting completed!\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_data, train_labels, test_size=0.2, stratify=train_labels)\n",
    "print(\"Splitting completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The micro average f1_score for the xgb classifier is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7287465704802287"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating an xgb classifier\n",
    "xg_cl = xgb.XGBClassifier(objective='multi:softmax', num_class=3, n_estimators=100, max_depth=10)\n",
    "# Fitting the model\n",
    "xg_cl.fit(X_train, y_train)\n",
    "# Getting the micro average f1_score \n",
    "print(\"The micro average f1_score for the xgb classifier is:\")\n",
    "f1_score(y_test, xg_cl.predict(X_test), average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The micro average f1_score for the Random Forest Classifier is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7245831814431803"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating a Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=30)\n",
    "# Fitting the model\n",
    "rf.fit(X_train, y_train)\n",
    "# Getting the micro average f1_score\n",
    "print(\"The micro average f1_score for the Random Forest Classifier is:\")\n",
    "f1_score(y_test, rf.predict(X_test), average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The micro average f1_score for the adaboost classifier is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6669480631607222"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating an AdaBoost Classifier\n",
    "ada = AdaBoostClassifier(n_estimators=500)\n",
    "# Fitting the model\n",
    "ada.fit(X_train, y_train)\n",
    "# Getting the micro average f1_score\n",
    "print(\"The micro average f1_score for the adaboost classifier is:\")\n",
    "f1_score(y_test, ada.predict(X_test), average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the previous models\n",
    "\n",
    "We will use a Voting Classifier to combine the three previous models we've created. We will set the parameter *voting = soft* in order to get the mean of the probabilities that an outcome belongs to a specific class. These probabilities are of course, determined by the previous models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step completed!\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the Voting Classifier\n",
    "clf_voting = VotingClassifier(\n",
    "                    estimators=[\n",
    "                                ('xgboost', xg_cl),\n",
    "                                ('random forest', rf),\n",
    "                                ('adaboost', ada)],\n",
    "                     voting='soft')\n",
    "print(\"Step completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The micro average f1_score for the Voting classifier is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7364593925672953"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the Voting Classifier\n",
    "clf_voting.fit(X_train, y_train)\n",
    "# Getting the micro average f1_score\n",
    "print(\"The micro average f1_score for the Voting classifier is:\")\n",
    "f1_score(y_test, clf_voting.predict(X_test), average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we combine the previous models, we see that we obtain a better micro average f1_score. Therefore we'll use the voting classifier as the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing datas for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    \"\"\"This function takes a dataframe. Then, it selects the appropriate features, encode categorical variables, and return\n",
    "    a dataframe usable for the model prediction\"\"\"\n",
    "    X = df[features]\n",
    "    categorical_values = X.select_dtypes(include=['object'])\n",
    "    numeric_values = X.select_dtypes(include=['int64'])\n",
    "    categorical_encoded = pd.get_dummies(categorical_values, drop_first=True)\n",
    "    new_data = pd.concat([numeric_values, categorical_encoded], axis=1)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the test values\n",
    "test_values = pd.read_csv('C:/Users/user/Documents/1. E-Learning/2019 Program/Data Science Machine Learning and Deep Learning/Driven Data/Modeling EarthQuake Damage/test_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the test values\n",
    "X = preprocessing(test_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Predicting the target variable\n",
    "predictions = clf_voting.predict(X)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86868 predictions made\n"
     ]
    }
   ],
   "source": [
    "print(\"{} predictions made\".format(len(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the submission into the right format\n",
    "submissions = test_values.copy()\n",
    "submissions['damage_grade'] = pd.Series(predictions)\n",
    "submissions[['building_id', 'damage_grade']].to_csv('damage_predictions_2.csv', index=False)\n",
    "print(\"File created!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
